# âš¡ Guide de DÃ©marrage Rapide - 5 Minutes

Ce guide vous permettra de lancer la pile ELK en moins de 5 minutes.

---

## ğŸ“‹ PrÃ©requis

Avant de commencer, assurez-vous d'avoir :

- âœ… **Docker** installÃ© ([TÃ©lÃ©charger](https://www.docker.com/products/docker-desktop))
- âœ… **Docker Compose** installÃ© (inclus avec Docker Desktop)
- âœ… **8 GB RAM minimum** disponible
- âœ… **10 GB d'espace disque** libre

### VÃ©rifier l'installation

```bash
docker --version
# Docker version 20.10.17 ou supÃ©rieur

docker-compose --version
# docker-compose version 1.29.2 ou supÃ©rieur
```

---

## ğŸš€ Installation en 5 Ã‰tapes

### Ã‰tape 1ï¸âƒ£ : Cloner le Projet

```bash
git clone https://github.com/Boutanfitsalma/firefox-build-log-monitoring-elk.git
cd firefox-build-log-monitoring-elk
```

### Ã‰tape 2ï¸âƒ£ : Configurer l'Environnement

```bash
# Copier le fichier d'environnement

```

### Ã‰tape 3ï¸âƒ£ : PrÃ©parer le RÃ©pertoire des Logs

```bash
# CrÃ©er le dossier pour les logs
mkdir -p logs

# Ajouter un fichier .gitkeep pour garder le dossier dans Git
touch logs/.gitkeep
```

**Important** : Placer vos fichiers de logs `.txt` dans le dossier `logs/` avant de dÃ©marrer.

### Ã‰tape 4ï¸âƒ£ : DÃ©marrer la Pile ELK

```bash
# DÃ©marrer tous les services en arriÃ¨re-plan
docker-compose up -d

# VÃ©rifier que tout est opÃ©rationnel
docker-compose ps
```

**Sortie attendue** :

```
NAME                COMMAND                  SERVICE             STATUS
elasticsearch       "/bin/tini -- /usr/lâ€¦"   elasticsearch       Up (healthy)
filebeat            "/usr/bin/docker-entâ€¦"   filebeat            Up
kibana              "/bin/tini -- /usr/lâ€¦"   kibana              Up
logstash            "/usr/local/bin/dockâ€¦"   logstash            Up
```

### Ã‰tape 5ï¸âƒ£ : AccÃ©der Ã  Kibana

```bash
# Attendre 30-60 secondes que Kibana soit prÃªt
# Puis ouvrir dans le navigateur :
```

ğŸŒ **Kibana** : http://localhost:5601

---

## ğŸ¯ VÃ©rifications Post-DÃ©marrage

### 1. VÃ©rifier Elasticsearch

```bash
curl http://localhost:9200/_cluster/health?pretty
```

**RÃ©ponse attendue** : `"status" : "green"` ou `"yellow"`

### 2. VÃ©rifier les Index CrÃ©Ã©s

```bash
curl http://localhost:9200/_cat/indices?v
```

Vous devriez voir un index `firefox-logs-*`.

### 3. VÃ©rifier Filebeat

```bash
docker-compose logs filebeat | tail -20
```

Chercher des lignes comme :
```
INFO    [publisher_pipeline_output]    pipeline/output.go:143    Connection to backoff(async(tcp://logstash:5044)) established
```

### 4. AccÃ©der au Dashboard Kibana

1. Aller sur http://localhost:5601
2. Cliquer sur le menu â˜° (hamburger)
3. Aller dans **Analytics** > **Discover**
4. SÃ©lectionner l'index pattern `firefox-logs-*`
5. Vous devriez voir vos logs !

---

## ğŸ“Š CrÃ©er votre Premier Dashboard

### MÃ©thode 1 : Import Automatique (RecommandÃ©)

Si vous avez un export de dashboard :

1. Aller dans **Stack Management** > **Saved Objects**
2. Cliquer sur **Import**
3. SÃ©lectionner le fichier `dashboard-export.ndjson`
4. Cliquer sur **Import**

### MÃ©thode 2 : CrÃ©ation Manuelle

1. Aller dans **Analytics** > **Dashboard**
2. Cliquer sur **Create dashboard**
3. Cliquer sur **Create visualization**
4. Choisir le type de visualisation (ex: **Metric**)
5. Configurer la visualisation
6. Sauvegarder

**Visualisations recommandÃ©es** :
- **Metric** : Nombre total de logs
- **Pie Chart** : RÃ©partition des statuts
- **Line Chart** : Volume dans le temps
- **Data Table** : Top fichiers actifs

---

## ğŸ” Activer la DÃ©tection d'Anomalies

### PrÃ©requis

âš ï¸ **Important** : La dÃ©tection d'anomalies nÃ©cessite une **licence Basic (gratuite)** d'Elasticsearch.

### Activation

1. Aller dans **Machine Learning** dans le menu Kibana
2. Cliquer sur **Create new job**
3. SÃ©lectionner **Advanced job**
4. Configurer :
   - **Index pattern** : `firefox-logs-*`
   - **Detector** : `count`
   - **Partition field** : `log.file.path.keyword`
   - **Bucket span** : `15m`
5. Cliquer sur **Create job**
6. Cliquer sur **Start**

### Visualiser les Anomalies

1. Aller dans **Machine Learning** > **Anomaly Explorer**
2. SÃ©lectionner votre job
3. Explorer les anomalies dÃ©tectÃ©es

---

## ğŸ›‘ ArrÃªter la Pile

```bash
# ArrÃªter tous les services
docker-compose down

# ArrÃªter ET supprimer les volumes (âš ï¸ perte de donnÃ©es)
docker-compose down -v
```

---

## ğŸ”„ RedÃ©marrer la Pile

```bash
# DÃ©marrer
docker-compose up -d

# RedÃ©marrer un service spÃ©cifique
docker-compose restart logstash
```

---

## ğŸ› ProblÃ¨mes Courants

### ProblÃ¨me 1 : "Port already in use"

**Erreur** : `Bind for 0.0.0.0:9200 failed: port is already allocated`

**Solution** :
```bash
# Trouver le processus qui utilise le port
# Windows
netstat -ano | findstr :9200

# Linux/Mac
lsof -i :9200

# Tuer le processus ou changer le port dans .env
```

### ProblÃ¨me 2 : Elasticsearch ne dÃ©marre pas

**Erreur** : `max virtual memory areas vm.max_map_count [65530] is too low`

**Solution** :

**Linux/Mac** :
```bash
sudo sysctl -w vm.max_map_count=262144
```

**Windows (WSL2)** :
```powershell
wsl -d docker-desktop
sysctl -w vm.max_map_count=262144
```

### ProblÃ¨me 3 : Filebeat ne trouve pas les logs

**SymptÃ´me** : Aucun log dans Kibana

**Solution** :
1. VÃ©rifier que les fichiers `.txt` sont bien dans `./logs/`
2. VÃ©rifier les permissions :
   ```bash
   chmod -R 755 logs/
   ```
3. Regarder les logs Filebeat :
   ```bash
   docker-compose logs filebeat
   ```

### ProblÃ¨me 4 : "Out of memory"

**SymptÃ´me** : Services qui crashent

**Solution** :
1. Augmenter la RAM allouÃ©e Ã  Docker (Settings > Resources)
2. RÃ©duire la mÃ©moire JVM dans `.env` :
   ```bash
   ES_JAVA_OPTS=-Xms256m -Xmx256m
   LS_JAVA_OPTS=-Xms128m -Xmx128m
   ```

---

## ğŸ“š Ã‰tapes Suivantes

Maintenant que votre pile ELK fonctionne :

1. ğŸ“– Lire le [README complet](README.md)
2. ğŸ—ï¸ Explorer l'[Architecture dÃ©taillÃ©e](docs/ARCHITECTURE.md)
3. ğŸ“Š Consulter le [Rapport PDF](docs/Rapport_Projet_ELK.pdf)


---

